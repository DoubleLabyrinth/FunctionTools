#include "Base16.h"

BYTE Base16Decoding::InverseBase16Table[0x47] = {0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                                                 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                                                 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                                                 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                                                 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                                                 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                                                 0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07,
                                                 0x08, 0x09, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,
                                                 0x00, 0x0A, 0x0B, 0x0C, 0x0D, 0x0E, 0x0F};

SmartPointer<char> Base16Decoding::GetDecodedString(const BYTE* srcBytes, UINT64 BytesLength) {
    if(BytesLength & 0x01) return nullptr;
    char* Ret = (char*)malloc(sizeof(char) * (BytesLength >> 1) + 1);
    if(Ret == nullptr) return nullptr;
    for(UINT64 i = 0; i < BytesLength; i +=2) {
        Ret[i >> 1] = InverseBase16Table[srcBytes[i]] << 4;
        Ret[i >> 1] |= InverseBase16Table[srcBytes[i + 1]];
    }

    return Ret;
}
